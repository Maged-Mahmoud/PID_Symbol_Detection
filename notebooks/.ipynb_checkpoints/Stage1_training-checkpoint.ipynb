{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c34dba7-9fb8-4980-9a9c-6fb066eb1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from fastai.vision.all import *\n",
    "from natsort import natsorted\n",
    "import os, sys, gc, cv2, yaml\n",
    "from pathlib import Path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from utils.preprocess_utils import *\n",
    "from utils.stage1_utils import *\n",
    "from utils.yolo_utils import *\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa04f033-8cda-49f2-95f2-aef2f47f71e3",
   "metadata": {},
   "source": [
    "#### 1. Make train, val, test sets from full PIDs\n",
    "- **Ques:** Can you guess why full sheets are used to partition the datasets and not crops?\n",
    "- **Ans:** To prevent data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d68e29-e6a9-4de1-b5cb-fc65b8e9ced0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 10\n",
      "Train: 6, Val: 2, Test: 2\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = Path('../data/sample_dataset/original/') # directory containing full PIDs (original)\n",
    "train_ims, val_ims, test_ims = make_train_val_test_split(dataset_dir, train_val_test_ratio=[0.64, 0.16, 0.2])\n",
    "#print(f'train_ims: {train_ims} \\nval_ims: {val_ims} \\ntest_ims:{test_ims}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7accd0-0117-445f-8902-4caa6ec5f5f3",
   "metadata": {},
   "source": [
    "#### 2. Make train, val, test sets by selecting crops from full PIDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df04172-bef3-4f4b-a1f9-a2dfe09aa8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of class_Aware crops\n",
    "crops_folder_pth = Path('../data/sample_dataset/patches_class_aware/')\n",
    "train_crops_aware, val_crops_aware, test_crops_aware = select_crops(full_pid_splits = [train_ims, val_ims, test_ims], crops_folder_pth=crops_folder_pth)\n",
    "\n",
    "# Get list of class_Agnostoc crops\n",
    "crops_folder_pth = Path('../data/sample_dataset/patches_class_agnostic/')\n",
    "train_crops_agnostic, val_crops_agnostic, test_crops_agnostic = select_crops(full_pid_splits = [train_ims, val_ims, test_ims], crops_folder_pth=crops_folder_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e31d7-1f26-46e5-a48f-295fa9ac40cf",
   "metadata": {},
   "source": [
    "#### 3. Make folders for training YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f3ca2b-5847-45ab-bada-7ea822c5bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 100 files to train folder\n",
      "Copied 24 files to val folder\n",
      "Copied 24 files to test folder\n"
     ]
    }
   ],
   "source": [
    "# for class Aware\n",
    "make_yolo_folders(dir_name='yolo_class_aware', \n",
    "                  train_images=train_crops_aware, \n",
    "                  val_images=val_crops_aware, \n",
    "                  test_images=test_crops_aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed828fee-79e7-413d-9920-0f73f7e4943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 100 files to train folder\n",
      "Copied 24 files to val folder\n",
      "Copied 24 files to test folder\n"
     ]
    }
   ],
   "source": [
    "# for class Agnostic\n",
    "make_yolo_folders(dir_name='yolo_class_agnostic', \n",
    "                  train_images=train_crops_agnostic, \n",
    "                  val_images=val_crops_agnostic, \n",
    "                  test_images=test_crops_agnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "622ce770-f88b-48f1-9826-cd1d374defae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for full pids (Not recommended) because A) Dataset is small and B) Images are of large size)\n",
    "to_run = False\n",
    "if to_run:\n",
    "    make_yolo_folders(dir_name='yolo_full', \n",
    "                      train_images=train_ims, \n",
    "                      val_images=val_ims, \n",
    "                      test_images=test_ims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add8425-7d96-4c02-820b-522c3b7a7926",
   "metadata": {},
   "source": [
    "#### 4. Train yolo models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c3e75-c695-417a-8c2e-51b9dfd56776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yolo_model(yaml_filename = , epochs=2, patience=1, batch_size=8, imgsz=1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
